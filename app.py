# ==================================================
# PRO-DATA AI AGENT: FREELANCE EDITION
# Author: Varun Walekar
# Version: 3.0 (Production Ready)
# ==================================================

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import time
from fpdf import FPDF
from io import BytesIO

# Machine Learning Imports
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, r2_score

# --- PAGE CONFIGURATION ---
st.set_page_config(
    page_title="ProData AI Analyst",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CUSTOM CSS FOR PROFESSIONAL LOOK ---
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    h1, h2, h3 { font-family: 'Sans-Serif'; color: #2c3e50; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #007bff; color: white; font-weight: bold;}
    .stButton>button:hover { background-color: #0056b3; border: none; }
    .metric-card { background-color: #ffffff; padding: 20px; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# --- CLASS: PDF GENERATOR ---
class PDFReport(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, 'AI Data Analysis Report', 0, 1, 'C')
        self.ln(5)
        self.set_font('Arial', 'I', 10)
        self.cell(0, 10, 'Generated by ProData AI Agent', 0, 1, 'C')
        self.ln(10)

    def footer(self):
        self.set_y(-15)
        self.set_font('Arial', 'I', 8)
        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')

    def chapter_title(self, title):
        self.set_font('Arial', 'B', 12)
        self.cell(0, 10, title, 0, 1, 'L')
        self.ln(2)

    def chapter_body(self, body):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 8, body)
        self.ln()

# --- HELPER FUNCTION: SMART CLEANER ---
def smart_cleaner(df):
    """
    Intelligently cleans a dataset:
    1. Standardizes column names.
    2. Drops empty columns.
    3. Fills numeric missing values with Median.
    4. Fills categorical missing values with Mode.
    """
    df = df.copy()
    
    # 1. Standardize Headers
    df.columns = [str(c).strip().lower().replace(" ", "_").replace("-", "_") for c in df.columns]
    
    # 2. Remove Empty Columns
    df = df.dropna(axis=1, how='all')

    # 3. Intelligent Filling
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            # Fill numbers with Median (Robust to outliers)
            df[col] = df[col].fillna(df[col].median())
        else:
            # Fill text with Mode (Most frequent) or "Unknown"
            if not df[col].mode().empty:
                df[col] = df[col].fillna(df[col].mode()[0])
            else:
                df[col] = df[col].fillna("Unknown")
    
    return df

# --- MAIN APP LOGIC ---

def main():
    # Session State Initialization
    if 'df_clean' not in st.session_state:
        st.session_state['df_clean'] = None
    if 'model_score' not in st.session_state:
        st.session_state['model_score'] = None

    # --- SIDEBAR ---
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/2103/2103633.png", width=80)
        st.title("ProData AI")
        st.write("Professional Automated Data Analyst")
        st.divider()
        
        uploaded_file = st.file_uploader("üìÇ Upload Dataset", type=['csv', 'xlsx'])
        
        st.info("Supported formats: .CSV, .XLSX")
        st.caption("v3.0 - Freelance Edition")

    # --- HOME PAGE (If no data) ---
    if uploaded_file is None:
        st.title("üëã Welcome to ProData AI")
        st.markdown("""
        ### Your Virtual Data Scientist
        This tool automates the boring parts of data analysis so you can focus on insights.
        
        **Capabilities:**
        - üßπ **Auto-Clean:** Detects and fixes messy data instantly.
        - üìà **Smart Charts:** Interactive visualizations powered by Plotly.
        - ü§ñ **AutoML:** Trains Predictive Models (Regression/Classification) automatically.
        - üìÑ **PDF Reports:** Generates professional audit reports for clients.
        
        *üëà Upload a file in the sidebar to begin!*
        """)
        
        # Example Data Demo
        if st.button("Load Demo Data (Titanic)"):
            url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
            df = pd.read_csv(url)
            st.session_state['df_clean'] = smart_cleaner(df)
            st.rerun()

    # --- DASHBOARD (If data exists) ---
    else:
        # Load Data once
        if st.session_state['df_clean'] is None:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.session_state['df_clean'] = df  # Save initial raw data

        df = st.session_state['df_clean']

        # --- LAYOUT TABS ---
        tab1, tab2, tab3, tab4 = st.tabs([
            "üîç Data Inspector", 
            "üìä Visual Analytics", 
            "ü§ñ ML Studio", 
            "üìë Client Report"
        ])

        # --- TAB 1: INSPECTOR ---
        with tab1:
            st.header("üîç Data Inspector & Cleaner")
            
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Rows", df.shape[0])
            c2.metric("Columns", df.shape[1])
            c3.metric("Missing Values", df.isna().sum().sum())
            c4.metric("Duplicates", df.duplicated().sum())

            col_action, col_preview = st.columns([1, 3])
            
            with col_action:
                st.markdown("### üõ† Actions")
                if st.button("‚ú® Run Smart Cleaner"):
                    with st.spinner("Standardizing & Cleaning..."):
                        time.sleep(1)
                        df_cleaned = smart_cleaner(df)
                        st.session_state['df_clean'] = df_cleaned
                        st.success("Cleaned Successfully!")
                        st.rerun()
                
                if st.button("üîÑ Reset Data"):
                    st.session_state['df_clean'] = None
                    st.rerun()

            with col_preview:
                st.markdown("### üìã Data Preview")
                st.dataframe(df.head(10), use_container_width=True)
                
                with st.expander("Show Column Types"):
                    st.json(df.dtypes.astype(str).to_dict())

        # --- TAB 2: VISUALS ---
        with tab2:
            st.header("üìä Interactive Visual Analytics")
            
            c1, c2 = st.columns([1, 3])
            
            with c1:
                st.subheader("Chart Config")
                chart_type = st.selectbox("Chart Type", ["Scatter Plot", "Line Chart", "Bar Chart", "Histogram", "Box Plot"])
                
                numeric_cols = df.select_dtypes(include=np.number).columns
                all_cols = df.columns
                
                x_axis = st.selectbox("X-Axis", all_cols)
                y_axis = st.selectbox("Y-Axis", numeric_cols)
                color_by = st.selectbox("Color By (Optional)", [None] + list(all_cols))
            
            with c2:
                if chart_type == "Scatter Plot":
                    fig = px.scatter(df, x=x_axis, y=y_axis, color=color_by, title=f"{y_axis} vs {x_axis}")
                elif chart_type == "Line Chart":
                    fig = px.line(df, x=x_axis, y=y_axis, color=color_by, title=f"{y_axis} Trend")
                elif chart_type == "Bar Chart":
                    fig = px.bar(df, x=x_axis, y=y_axis, color=color_by, title=f"{y_axis} by {x_axis}")
                elif chart_type == "Histogram":
                    fig = px.histogram(df, x=x_axis, color=color_by, title=f"Distribution of {x_axis}")
                elif chart_type == "Box Plot":
                    fig = px.box(df, x=x_axis, y=y_axis, color=color_by, title=f"{y_axis} Distribution by {x_axis}")
                
                st.plotly_chart(fig, use_container_width=True)

        # --- TAB 3: ML STUDIO ---
        with tab3:
            st.header("ü§ñ AutoML Studio")
            st.write("Train an AI model to predict a target variable.")

            c1, c2 = st.columns([1, 2])
            
            with c1:
                target = st.selectbox("üéØ Target Variable (What to predict?)", df.columns)
                features = st.multiselect("‚öôÔ∏è Features (Predictors)", [c for c in df.columns if c != target])
                
                split_size = st.slider("Train/Test Split", 0.1, 0.5, 0.2)
                
                start_train = st.button("üöÄ Train Model")

            with c2:
                if start_train and features:
                    try:
                        with st.spinner("Training best fit model..."):
                            # Prepare Data
                            X = df[features]
                            y = df[target]
                            
                            # Simple Encoding for Categorical Features
                            X = pd.get_dummies(X, drop_first=True)
                            
                            # Determine Task Type
                            is_classification = False
                            if pd.api.types.is_object_dtype(y) or y.nunique() < 10:
                                is_classification = True
                                le = LabelEncoder()
                                y = le.fit_transform(y)
                            
                            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_size, random_state=42)
                            
                            # Pipeline Construction
                            if is_classification:
                                model = RandomForestClassifier(n_estimators=100, random_state=42)
                                model_type = "Classification (Random Forest)"
                            else:
                                model = RandomForestRegressor(n_estimators=100, random_state=42)
                                model_type = "Regression (Random Forest)"
                                
                            pipeline = Pipeline([
                                ('scaler', StandardScaler()),
                                ('model', model)
                            ])
                            
                            pipeline.fit(X_train, y_train)
                            y_pred = pipeline.predict(X_test)
                            
                            # Evaluation
                            if is_classification:
                                score = accuracy_score(y_test, y_pred)
                                metric_name = "Accuracy"
                            else:
                                score = r2_score(y_test, y_pred)
                                metric_name = "R¬≤ Score"
                            
                            st.session_state['model_score'] = f"{round(score*100, 2)}%"
                            st.session_state['target_col'] = target
                            
                            st.success(f"Model Trained: {model_type}")
                            st.metric(metric_name, f"{round(score*100, 2)}%")
                            
                            # Feature Importance Chart
                            importances = pipeline.named_steps['model'].feature_importances_
                            feat_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance', ascending=True)
                            fig_imp = px.bar(feat_df, x='Importance', y='Feature', orientation='h', title="Feature Importance")
                            st.plotly_chart(fig_imp, use_container_width=True)
                            
                    except Exception as e:
                        st.error(f"Training Failed: {str(e)}")
                        st.error("Tip: Try cleaning the data first or selecting different columns.")
                elif start_train and not features:
                    st.warning("Please select at least one feature.")

        # --- TAB 4: REPORTS ---
        with tab4:
            st.header("üìë Export & Reports")
            st.write("Generate professional deliverables for your client.")
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                st.subheader("üì• Cleaned Data")
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="Download CSV",
                    data=csv,
                    file_name="prodata_cleaned_export.csv",
                    mime="text/csv"
                )
            
            with col_b:
                st.subheader("üìÑ PDF Audit Report")
                if st.button("Generate PDF Report"):
                    # Create PDF Object
                    pdf = PDFReport()
                    pdf.add_page()
                    
                    # 1. Summary
                    pdf.chapter_title("1. Executive Summary")
                    summary_text = (f"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns. "
                                    f"Data quality analysis detected {df.isna().sum().sum()} missing values initially. "
                                    f"Optimization processes have standardized the structure.")
                    pdf.chapter_body(summary_text)
                    
                    # 2. Insights
                    pdf.chapter_title("2. Key Insights")
                    num_cols = df.select_dtypes(include=np.number).columns
                    if len(num_cols) > 0:
                        insight_text = f"Top Numeric Variable: {num_cols[0]}\nAverage Value: {round(df[num_cols[0]].mean(), 2)}\nMax Value: {df[num_cols[0]].max()}"
                        pdf.chapter_body(insight_text)
                    
                    # 3. AI Model
                    pdf.chapter_title("3. AI Predictive Analysis")
                    if st.session_state['model_score']:
                        model_text = (f"Target Variable: {st.session_state.get('target_col', 'N/A')}\n"
                                      f"Model Confidence Score: {st.session_state['model_score']}")
                        pdf.chapter_body(model_text)
                    else:
                        pdf.chapter_body("No AI model was trained during this session.")
                        
                    # Output PDF
                    pdf_output = pdf.output(dest='S').encode('latin-1')
                    
                    st.download_button(
                        label="Download PDF Report",
                        data=pdf_output,
                        file_name="ProData_AI_Audit_Report.pdf",
                        mime="application/pdf"
                    )

if __name__ == "__main__":
    main()
